"""
LaMP (Language Model Personalization) Benchmark í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
2-stage vs 3-stage íŒŒì´í”„ë¼ì¸ ë¹„êµ

LaMP ë²¤ì¹˜ë§ˆí¬ íƒœìŠ¤í¬:
- LaMP-1: Personalized Citation Identification (ë…¼ë¬¸ ì¸ìš© ì˜ˆì¸¡)
- LaMP-2: Personalized News Categorization (ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜)
- LaMP-3: Personalized Product Rating (ì œí’ˆ í‰ì  ì˜ˆì¸¡)
- LaMP-4: Personalized News Headline Generation (ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ìƒì„±)
- LaMP-5: Personalized Scholarly Title Generation (ë…¼ë¬¸ ì œëª© ìƒì„±)
- LaMP-6: Personalized Email Subject Generation (ì´ë©”ì¼ ì œëª© ìƒì„±)
- LaMP-7: Personalized Tweet Paraphrasing (íŠ¸ìœ— íŒ¨ëŸ¬í”„ë ˆì´ì§•)

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” LaMP ìŠ¤íƒ€ì¼ì˜ ê°œì¸í™” ê²€ìƒ‰ íƒœìŠ¤í¬ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤.
"""

import asyncio
import json
import os
import sys
import time
import math
import random
from datetime import datetime, timedelta
from typing import List, Dict, Any, Tuple, Optional
from dataclasses import dataclass
from collections import defaultdict
import uuid
import numpy as np

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from dotenv import load_dotenv
load_dotenv()

from openai import OpenAI
from qdrant_client import QdrantClient
from qdrant_client.models import (
    VectorParams, Distance, PointStruct,
    Filter, FieldCondition, MatchValue,
    SearchParams
)

# Cohere for reranking
try:
    import cohere
    COHERE_AVAILABLE = True
except ImportError:
    COHERE_AVAILABLE = False
    print("âš ï¸ Cohere not installed. Reranking will be disabled.")


@dataclass
class LaMP_Profile:
    """LaMP ì‚¬ìš©ì í”„ë¡œí•„ ë°ì´í„°"""
    user_id: str
    profile_items: List[Dict[str, Any]]  # ê³¼ê±° í™œë™ ê¸°ë¡
    task_type: str  # LaMP-1 ~ LaMP-7


@dataclass
class LaMP_Query:
    """LaMP ì¿¼ë¦¬ ë°ì´í„°"""
    query_id: str
    user_id: str
    query_text: str
    task_type: str
    ground_truth: str  # ì •ë‹µ
    relevant_profile_ids: List[str]  # ê´€ë ¨ í”„ë¡œí•„ ì•„ì´í…œ ID


class BM25:
    """BM25 ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„"""

    def __init__(self, k1: float = 1.5, b: float = 0.75):
        self.k1 = k1
        self.b = b
        self.doc_freqs = {}
        self.doc_lens = []
        self.avg_doc_len = 0
        self.corpus_size = 0
        self.documents = []
        self.tokenized_docs = []

    def tokenize(self, text: str) -> List[str]:
        """ê°„ë‹¨í•œ í† í¬ë‚˜ì´ì €"""
        import re
        text = text.lower()
        tokens = re.findall(r'\b\w+\b', text)
        return tokens

    def fit(self, documents: List[str]):
        """ë¬¸ì„œ ì»¬ë ‰ì…˜ ì¸ë±ì‹±"""
        self.documents = documents
        self.corpus_size = len(documents)
        self.tokenized_docs = [self.tokenize(doc) for doc in documents]

        # ë¬¸ì„œ ê¸¸ì´ ê³„ì‚°
        self.doc_lens = [len(doc) for doc in self.tokenized_docs]
        self.avg_doc_len = sum(self.doc_lens) / self.corpus_size if self.corpus_size > 0 else 0

        # ë¬¸ì„œ ë¹ˆë„ ê³„ì‚°
        self.doc_freqs = defaultdict(int)
        for doc in self.tokenized_docs:
            for term in set(doc):
                self.doc_freqs[term] += 1

    def get_scores(self, query: str) -> List[float]:
        """ì¿¼ë¦¬ì— ëŒ€í•œ ëª¨ë“  ë¬¸ì„œì˜ BM25 ì ìˆ˜ ê³„ì‚°"""
        query_tokens = self.tokenize(query)
        scores = []

        for idx, doc in enumerate(self.tokenized_docs):
            score = 0.0
            doc_len = self.doc_lens[idx]

            term_freqs = defaultdict(int)
            for term in doc:
                term_freqs[term] += 1

            for term in query_tokens:
                if term not in term_freqs:
                    continue

                tf = term_freqs[term]
                df = self.doc_freqs.get(term, 0)

                if df == 0:
                    continue

                idf = math.log((self.corpus_size - df + 0.5) / (df + 0.5) + 1)
                tf_norm = (tf * (self.k1 + 1)) / (tf + self.k1 * (1 - self.b + self.b * doc_len / self.avg_doc_len))
                score += idf * tf_norm

            scores.append(score)

        return scores

    def search(self, query: str, top_k: int = 10) -> List[Tuple[int, float]]:
        """ìƒìœ„ kê°œ ë¬¸ì„œ ê²€ìƒ‰"""
        scores = self.get_scores(query)
        indexed_scores = [(i, score) for i, score in enumerate(scores)]
        indexed_scores.sort(key=lambda x: x[1], reverse=True)
        return indexed_scores[:top_k]


class LaMP_Benchmark:
    """LaMP ë²¤ì¹˜ë§ˆí¬ í‰ê°€ í´ë˜ìŠ¤"""

    def __init__(self):
        self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.qdrant = QdrantClient(host="localhost", port=6333)
        self.collection_name = "lamp_benchmark"
        self.embedding_model = "text-embedding-3-large"
        self.embedding_dim = 3072

        # Cohere client for reranking
        self.cohere_client = None
        if COHERE_AVAILABLE and os.getenv("COHERE_API_KEY"):
            self.cohere_client = cohere.Client(os.getenv("COHERE_API_KEY"))
            print("âœ… Cohere Reranking í™œì„±í™”")
        else:
            print("âš ï¸ Cohere Reranking ë¹„í™œì„±í™”")

        # BM25 ì¸ë±ìŠ¤
        self.bm25 = BM25()
        self.documents = []
        self.document_ids = []

    def generate_lamp_data(self, num_users: int = 10, items_per_user: int = 20) -> Tuple[List[LaMP_Profile], List[LaMP_Query]]:
        """
        LaMP ìŠ¤íƒ€ì¼ì˜ ê°œì¸í™” ë°ì´í„° ìƒì„±

        LaMP íƒœìŠ¤í¬ ì‹œë®¬ë ˆì´ì…˜:
        - LaMP-3 ìŠ¤íƒ€ì¼: ì œí’ˆ ë¦¬ë·°/í‰ì  ì˜ˆì¸¡
        - LaMP-4 ìŠ¤íƒ€ì¼: ì½˜í…ì¸  ì œëª© ìƒì„±
        - LaMP-6 ìŠ¤íƒ€ì¼: ì´ë©”ì¼/ë©”ì‹œì§€ ìŠ¤íƒ€ì¼
        """

        profiles = []
        queries = []

        # ì‚¬ìš©ìë³„ ê´€ì‹¬ì‚¬/ìŠ¤íƒ€ì¼ ì •ì˜
        user_personas = [
            {
                "name": "tech_enthusiast",
                "interests": ["AI", "machine learning", "programming", "tech gadgets"],
                "style": "technical",
                "preferred_products": ["laptop", "smartphone", "headphones", "smartwatch"],
                "rating_tendency": "critical"  # í‰ê·  3.5/5
            },
            {
                "name": "casual_user",
                "interests": ["movies", "music", "travel", "food"],
                "style": "casual",
                "preferred_products": ["camera", "speakers", "travel gear", "kitchen appliances"],
                "rating_tendency": "generous"  # í‰ê·  4.2/5
            },
            {
                "name": "professional",
                "interests": ["productivity", "business", "finance", "networking"],
                "style": "formal",
                "preferred_products": ["office equipment", "professional software", "books", "courses"],
                "rating_tendency": "balanced"  # í‰ê·  3.8/5
            },
            {
                "name": "creative",
                "interests": ["art", "design", "photography", "music production"],
                "style": "expressive",
                "preferred_products": ["graphics tablet", "camera", "software", "instruments"],
                "rating_tendency": "enthusiastic"  # í‰ê·  4.5/5
            },
            {
                "name": "student",
                "interests": ["studying", "budget products", "entertainment", "social"],
                "style": "informal",
                "preferred_products": ["textbooks", "laptop", "headphones", "snacks"],
                "rating_tendency": "varied"  # 2-5ì  ë‹¤ì–‘
            },
            {
                "name": "health_focused",
                "interests": ["fitness", "nutrition", "wellness", "outdoor activities"],
                "style": "motivational",
                "preferred_products": ["fitness tracker", "supplements", "workout gear", "healthy food"],
                "rating_tendency": "positive"
            },
            {
                "name": "minimalist",
                "interests": ["simple living", "quality over quantity", "sustainable products"],
                "style": "concise",
                "preferred_products": ["essential items", "quality tools", "durable goods"],
                "rating_tendency": "selective"
            },
            {
                "name": "gamer",
                "interests": ["video games", "esports", "gaming hardware", "streaming"],
                "style": "enthusiastic",
                "preferred_products": ["gaming PC", "monitor", "keyboard", "gaming chair"],
                "rating_tendency": "passionate"
            },
            {
                "name": "parent",
                "interests": ["family", "children", "home", "safety"],
                "style": "practical",
                "preferred_products": ["toys", "educational items", "home appliances", "safety equipment"],
                "rating_tendency": "thorough"
            },
            {
                "name": "senior",
                "interests": ["simplicity", "reliability", "health", "hobbies"],
                "style": "clear",
                "preferred_products": ["easy-to-use devices", "health monitors", "hobby supplies"],
                "rating_tendency": "appreciative"
            }
        ]

        # ì œí’ˆ ì¹´í…Œê³ ë¦¬ ë° ì˜ˆì‹œ
        product_templates = {
            "laptop": [
                "MacBook Pro 14ì¸ì¹˜ M3", "Dell XPS 15", "ThinkPad X1 Carbon",
                "ASUS ROG Zephyrus", "HP Spectre x360", "Surface Laptop 5"
            ],
            "smartphone": [
                "iPhone 15 Pro", "Samsung Galaxy S24 Ultra", "Google Pixel 8 Pro",
                "OnePlus 12", "Xiaomi 14 Pro"
            ],
            "headphones": [
                "Sony WH-1000XM5", "AirPods Pro 2", "Bose QuietComfort Ultra",
                "Sennheiser Momentum 4", "Audio-Technica ATH-M50x"
            ],
            "camera": [
                "Sony A7 IV", "Canon EOS R6 Mark II", "Nikon Z6 III",
                "Fujifilm X-T5", "Panasonic Lumix S5 II"
            ],
            "smartwatch": [
                "Apple Watch Ultra 2", "Samsung Galaxy Watch 6", "Garmin Fenix 7",
                "Fitbit Sense 2", "Google Pixel Watch 2"
            ],
            "keyboard": [
                "Keychron Q1 Pro", "Logitech MX Keys", "HHKB Professional",
                "Das Keyboard 4", "Corsair K100 RGB"
            ],
            "monitor": [
                "LG UltraFine 5K", "Dell UltraSharp U2723QE", "ASUS ProArt PA32UCG",
                "Samsung Odyssey G9", "BenQ PD3220U"
            ],
            "books": [
                "Atomic Habits", "Deep Work", "The Psychology of Money",
                "Clean Code", "Thinking, Fast and Slow"
            ]
        }

        # ë¦¬ë·° í…œí”Œë¦¿
        review_templates = {
            "technical": [
                "ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ {product}ëŠ” {metric}ì—ì„œ {score}ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. {detail}",
                "ê¸°ìˆ ì  ê´€ì ì—ì„œ {product}ì˜ {feature}ëŠ” {assessment}. íŠ¹íˆ {highlight}ê°€ ì¸ìƒì ì…ë‹ˆë‹¤.",
                "{product} ì‚¬ìš© í›„ {duration} ê²½ê³¼. {technical_analysis}. ì¢…í•© í‰ì : {rating}/5"
            ],
            "casual": [
                "{product} ì§„ì§œ ì¢‹ì•„ìš”! {reason} ë•ë¶„ì— {benefit}. ê°•ì¶”!",
                "ì´ê±° ì‚¬ê¸¸ ì˜í–ˆë‹¤~ {product} {positive}í•˜ê³  {positive2}í•´ì„œ ë§Œì¡±!",
                "{product} ì“´ ì§€ {duration}ëëŠ”ë° {experience}. {conclusion}"
            ],
            "formal": [
                "{product}ì— ëŒ€í•œ í‰ê°€ì…ë‹ˆë‹¤. {overview}. ì¥ì : {pros}. ë‹¨ì : {cons}. ê²°ë¡ : {verdict}",
                "ì—…ë¬´ìš©ìœ¼ë¡œ {product}ë¥¼ {duration} ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. {professional_assessment}",
                "{product}ì˜ ê°€ì„±ë¹„ë¥¼ ë¶„ì„í•˜ë©´ {analysis}. ì¶”ì²œ ëŒ€ìƒ: {target}"
            ],
            "expressive": [
                "ì™€! {product} ì™„ì „ ì‚¬ë‘í•´ìš” ğŸ’• {emotional_response} {creative_use}",
                "{product}ë¡œ {creative_work} í–ˆëŠ”ë° ê²°ê³¼ë¬¼ì´ {result}! {enthusiasm}",
                "ì˜ˆìˆ ê°€ ê´€ì ì—ì„œ {product}ëŠ” {artistic_assessment}. ì˜ê°ì„ ì£¼ëŠ” ì œí’ˆ!"
            ],
            "informal": [
                "ã…‹ã…‹ {product} ê°€ì„±ë¹„ ë¯¸ì³¤ìŒ {benefit} {slang_positive}",
                "{product} ì†”ì§ í›„ê¸°: {honest_opinion} ê·¼ë° {but} {conclusion}",
                "í•™ìƒ ì…ì¥ì—ì„œ {product}ëŠ” {student_perspective} {emoji}"
            ]
        }

        for user_idx in range(min(num_users, len(user_personas))):
            persona = user_personas[user_idx]
            user_id = f"user_{user_idx + 1}"

            profile_items = []

            # ì‚¬ìš©ìë³„ í”„ë¡œí•„ ì•„ì´í…œ ìƒì„± (ê³¼ê±° ë¦¬ë·°/í™œë™)
            for item_idx in range(items_per_user):
                # ì œí’ˆ ì¹´í…Œê³ ë¦¬ ì„ íƒ (ì‚¬ìš©ì ì„ í˜¸ ë°˜ì˜)
                if random.random() < 0.7:  # 70% í™•ë¥ ë¡œ ì„ í˜¸ ì¹´í…Œê³ ë¦¬
                    category = random.choice(persona["preferred_products"])
                    if category not in product_templates:
                        category = random.choice(list(product_templates.keys()))
                else:
                    category = random.choice(list(product_templates.keys()))

                product = random.choice(product_templates.get(category, product_templates["laptop"]))

                # í‰ì  ê²°ì • (ì‚¬ìš©ì ê²½í–¥ ë°˜ì˜)
                if persona["rating_tendency"] == "critical":
                    rating = random.choices([2, 3, 4, 5], weights=[10, 30, 40, 20])[0]
                elif persona["rating_tendency"] == "generous":
                    rating = random.choices([3, 4, 5], weights=[10, 40, 50])[0]
                elif persona["rating_tendency"] == "enthusiastic":
                    rating = random.choices([4, 5], weights=[30, 70])[0]
                elif persona["rating_tendency"] == "varied":
                    rating = random.randint(2, 5)
                else:
                    rating = random.choices([3, 4, 5], weights=[20, 50, 30])[0]

                # ë¦¬ë·° ìƒì„±
                style = persona["style"]
                template = random.choice(review_templates.get(style, review_templates["casual"]))

                review = self._generate_review(template, product, rating, persona)

                profile_item = {
                    "id": f"{user_id}_item_{item_idx}",
                    "product": product,
                    "category": category,
                    "rating": rating,
                    "review": review,
                    "date": (datetime.now() - timedelta(days=random.randint(1, 365))).isoformat(),
                    "style": style
                }
                profile_items.append(profile_item)

            profiles.append(LaMP_Profile(
                user_id=user_id,
                profile_items=profile_items,
                task_type="LaMP-3"  # Product rating prediction
            ))

            # ì¿¼ë¦¬ ìƒì„± (ìƒˆ ì œí’ˆì— ëŒ€í•œ í‰ì  ì˜ˆì¸¡)
            for q_idx in range(3):  # ì‚¬ìš©ìë‹¹ 3ê°œ ì¿¼ë¦¬
                # ê´€ë ¨ ìˆëŠ” ì¹´í…Œê³ ë¦¬ì—ì„œ ìƒˆ ì œí’ˆ ì„ íƒ
                query_category = random.choice(persona["preferred_products"])
                if query_category not in product_templates:
                    query_category = random.choice(list(product_templates.keys()))

                query_product = random.choice(product_templates[query_category])

                # ì‹¤ì œ ê´€ë ¨ í”„ë¡œí•„ ì•„ì´í…œ ì°¾ê¸° (ê°™ì€ ì¹´í…Œê³ ë¦¬)
                relevant_ids = [
                    item["id"] for item in profile_items
                    if item["category"] == query_category
                ][:5]

                # ì˜ˆìƒ í‰ì  ê³„ì‚° (ê´€ë ¨ ì•„ì´í…œ í‰ê· )
                related_ratings = [
                    item["rating"] for item in profile_items
                    if item["category"] == query_category
                ]
                expected_rating = round(sum(related_ratings) / len(related_ratings)) if related_ratings else 4

                query = LaMP_Query(
                    query_id=f"{user_id}_query_{q_idx}",
                    user_id=user_id,
                    query_text=f"{query_product}ì— ëŒ€í•´ ì´ ì‚¬ìš©ìëŠ” ì–´ë–¤ í‰ì ì„ ì¤„ê¹Œìš”? ì‚¬ìš©ìì˜ ê³¼ê±° ë¦¬ë·° ìŠ¤íƒ€ì¼ê³¼ ì„ í˜¸ë„ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.",
                    task_type="LaMP-3",
                    ground_truth=str(expected_rating),
                    relevant_profile_ids=relevant_ids
                )
                queries.append(query)

        return profiles, queries

    def _generate_review(self, template: str, product: str, rating: int, persona: Dict) -> str:
        """ë¦¬ë·° í…ìŠ¤íŠ¸ ìƒì„±"""
        # ê°„ë‹¨í•œ í…œí”Œë¦¿ ì±„ìš°ê¸°
        replacements = {
            "{product}": product,
            "{rating}": str(rating),
            "{duration}": random.choice(["1ì£¼ì¼", "2ì£¼", "í•œ ë‹¬", "3ê°œì›”", "6ê°œì›”"]),
            "{metric}": random.choice(["ì†ë„", "ë°°í„°ë¦¬", "ì„±ëŠ¥", "í’ˆì§ˆ"]),
            "{score}": random.choice(["ìš°ìˆ˜", "ì–‘í˜¸", "í‰ê·  ì´ìƒ", "ìµœìƒìœ„ê¶Œ"]),
            "{detail}": random.choice(["ì „ë°˜ì ìœ¼ë¡œ ë§Œì¡±", "ì¼ë¶€ ê°œì„  í•„ìš”", "ê¸°ëŒ€ ì´ìƒ"]),
            "{feature}": random.choice(["ë””ìì¸", "ì„±ëŠ¥", "ê°€ê²©", "ë‚´êµ¬ì„±"]),
            "{assessment}": random.choice(["í›Œë¥­í•©ë‹ˆë‹¤", "ê´œì°®ìŠµë‹ˆë‹¤", "ì•„ì‰½ìŠµë‹ˆë‹¤"]),
            "{highlight}": random.choice(["ë§ˆê°", "ì†ë„", "í¸ì˜ì„±", "ë””ìì¸"]),
            "{technical_analysis}": "ì„±ëŠ¥ ëŒ€ë¹„ ê°€ê²© í•©ë¦¬ì ",
            "{reason}": random.choice(["ë””ìì¸", "ì„±ëŠ¥", "ê°€ê²©"]),
            "{benefit}": random.choice(["ë§¤ì¼ ì‚¬ìš© ì¤‘", "ì™„ì „ í¸í•´ì§", "ìƒì‚°ì„± í–¥ìƒ"]),
            "{positive}": random.choice(["ì˜ˆì˜", "ë¹ ë¥´", "í¸í•˜"]),
            "{positive2}": random.choice(["ê°€ë²¼ì›Œ", "ì¡°ìš©í•´", "ì˜¤ë˜ê°€"]),
            "{experience}": "ë§Œì¡±ìŠ¤ëŸ½ê²Œ ì‚¬ìš© ì¤‘",
            "{conclusion}": random.choice(["ì¶”ì²œ!", "ê´œì°®ì•„ìš”", "ê°€ì„±ë¹„ ì¢‹ìŒ"]),
            "{overview}": "ì „ë°˜ì ìœ¼ë¡œ ìš°ìˆ˜í•œ ì œí’ˆ",
            "{pros}": "ì„±ëŠ¥, ë””ìì¸",
            "{cons}": "ê°€ê²©",
            "{verdict}": "ì¶”ì²œí•¨",
            "{professional_assessment}": "ì—…ë¬´ íš¨ìœ¨ì„± í–¥ìƒì— ë„ì›€",
            "{analysis}": "ê°€ê²© ëŒ€ë¹„ ì„±ëŠ¥ ìš°ìˆ˜",
            "{target}": "ì „ë¬¸ê°€/ì¼ë°˜ ì‚¬ìš©ì",
            "{emotional_response}": "ë„ˆë¬´ ì¢‹ì•„ì„œ í–‰ë³µí•´ìš”",
            "{creative_use}": "ì°½ì‘ í™œë™ì— í™œìš© ì¤‘",
            "{creative_work}": "ì‘í’ˆ",
            "{result}": "ëŒ€ë§Œì¡±",
            "{enthusiasm}": "ìµœê³ !",
            "{artistic_assessment}": "ì˜ê°ì„ ì£¼ëŠ” ë„êµ¬",
            "{honest_opinion}": "ë‚˜ì˜ì§€ ì•ŠìŒ",
            "{but}": "ê°€ê²©ì´ ì¢€...",
            "{student_perspective}": "í•™ìƒ ì˜ˆì‚°ì—” ë¶€ë‹´",
            "{slang_positive}": "ê°œì´ë“",
            "{emoji}": "ğŸ‘"
        }

        review = template
        for key, value in replacements.items():
            review = review.replace(key, value)

        return review

    def get_embedding(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
        response = self.openai_client.embeddings.create(
            model=self.embedding_model,
            input=text
        )
        return response.data[0].embedding

    def setup_collection(self):
        """Qdrant ì»¬ë ‰ì…˜ ì„¤ì •"""
        collections = self.qdrant.get_collections().collections
        if any(c.name == self.collection_name for c in collections):
            self.qdrant.delete_collection(self.collection_name)

        self.qdrant.create_collection(
            collection_name=self.collection_name,
            vectors_config=VectorParams(
                size=self.embedding_dim,
                distance=Distance.COSINE
            )
        )
        print(f"âœ… Collection '{self.collection_name}' ìƒì„± ì™„ë£Œ")

    def index_profiles(self, profiles: List[LaMP_Profile]):
        """í”„ë¡œí•„ ë°ì´í„° ì¸ë±ì‹±"""
        points = []
        self.documents = []
        self.document_ids = []

        for profile in profiles:
            for item in profile.profile_items:
                # ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ êµ¬ì„±
                text = f"ì œí’ˆ: {item['product']} | ì¹´í…Œê³ ë¦¬: {item['category']} | í‰ì : {item['rating']}/5 | ë¦¬ë·°: {item['review']}"

                embedding = self.get_embedding(text)

                point = PointStruct(
                    id=str(uuid.uuid4()),
                    vector=embedding,
                    payload={
                        "item_id": item["id"],
                        "user_id": profile.user_id,
                        "product": item["product"],
                        "category": item["category"],
                        "rating": item["rating"],
                        "review": item["review"],
                        "text": text,
                        "style": item["style"]
                    }
                )
                points.append(point)
                self.documents.append(text)
                self.document_ids.append(item["id"])

        # Qdrantì— ì—…ë¡œë“œ
        batch_size = 100
        for i in range(0, len(points), batch_size):
            self.qdrant.upsert(
                collection_name=self.collection_name,
                points=points[i:i+batch_size]
            )

        # BM25 ì¸ë±ìŠ¤ êµ¬ì¶•
        self.bm25.fit(self.documents)

        print(f"âœ… {len(points)}ê°œ í”„ë¡œí•„ ì•„ì´í…œ ì¸ë±ì‹± ì™„ë£Œ")

    def search_before(self, query: str, user_id: str, top_k: int = 5) -> Tuple[List[Dict], float]:
        """
        Before (2-stage): Vector Search â†’ Cohere Reranking
        """
        start_time = time.time()

        # 1ë‹¨ê³„: Vector Search
        query_embedding = self.get_embedding(query)

        search_result = self.qdrant.query_points(
            collection_name=self.collection_name,
            query=query_embedding,
            query_filter=Filter(
                must=[FieldCondition(key="user_id", match=MatchValue(value=user_id))]
            ),
            limit=top_k * 3
        )
        results = search_result.points

        candidates = [
            {
                "item_id": r.payload["item_id"],
                "text": r.payload["text"],
                "score": r.score,
                "product": r.payload["product"],
                "category": r.payload["category"],
                "rating": r.payload["rating"]
            }
            for r in results
        ]

        # 2ë‹¨ê³„: Cohere Reranking
        if self.cohere_client and candidates:
            try:
                # Rate limiting for Cohere Trial API (10 calls/min)
                time.sleep(3.5)  # ~17 calls/min max, safe margin

                rerank_response = self.cohere_client.rerank(
                    model="rerank-v3.5",
                    query=query,
                    documents=[c["text"] for c in candidates],
                    top_n=top_k
                )

                reranked = []
                for r in rerank_response.results:
                    candidate = candidates[r.index]
                    candidate["rerank_score"] = r.relevance_score
                    reranked.append(candidate)
                candidates = reranked
            except Exception as e:
                if "429" not in str(e):
                    print(f"Reranking error: {e}")
                candidates = candidates[:top_k]
        else:
            candidates = candidates[:top_k]

        latency = (time.time() - start_time) * 1000
        return candidates, latency

    def search_after(self, query: str, user_id: str, top_k: int = 5) -> Tuple[List[Dict], float]:
        """
        After (3-stage): Vector Search â†’ BM25 Hybrid â†’ Cohere Reranking
        """
        start_time = time.time()

        # 1ë‹¨ê³„: Vector Search
        query_embedding = self.get_embedding(query)

        search_result = self.qdrant.query_points(
            collection_name=self.collection_name,
            query=query_embedding,
            query_filter=Filter(
                must=[FieldCondition(key="user_id", match=MatchValue(value=user_id))]
            ),
            limit=top_k * 3
        )
        vector_results = search_result.points

        vector_candidates = {
            r.payload["item_id"]: {
                "item_id": r.payload["item_id"],
                "text": r.payload["text"],
                "vector_score": r.score,
                "product": r.payload["product"],
                "category": r.payload["category"],
                "rating": r.payload["rating"]
            }
            for r in vector_results
        }

        # 2ë‹¨ê³„: BM25 Hybrid
        bm25_results = self.bm25.search(query, top_k=top_k * 3)

        # í•´ë‹¹ ì‚¬ìš©ìì˜ ë¬¸ì„œë§Œ í•„í„°ë§
        user_doc_indices = [
            i for i, doc_id in enumerate(self.document_ids)
            if doc_id.startswith(user_id)
        ]

        bm25_filtered = [
            (idx, score) for idx, score in bm25_results
            if idx in user_doc_indices
        ]

        # BM25 ì ìˆ˜ ì •ê·œí™”
        if bm25_filtered:
            max_bm25 = max(score for _, score in bm25_filtered) if bm25_filtered else 1
            for idx, bm25_score in bm25_filtered:
                item_id = self.document_ids[idx]
                if item_id in vector_candidates:
                    vector_candidates[item_id]["bm25_score"] = bm25_score / max_bm25 if max_bm25 > 0 else 0

        # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚° (Vector 0.7, BM25 0.3)
        for item_id, candidate in vector_candidates.items():
            vector_score = candidate.get("vector_score", 0)
            bm25_score = candidate.get("bm25_score", 0)
            candidate["hybrid_score"] = 0.7 * vector_score + 0.3 * bm25_score

        # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ë¡œ ì •ë ¬
        candidates = sorted(
            vector_candidates.values(),
            key=lambda x: x.get("hybrid_score", 0),
            reverse=True
        )[:top_k * 2]

        # 3ë‹¨ê³„: Cohere Reranking
        if self.cohere_client and candidates:
            try:
                # Rate limiting for Cohere Trial API (10 calls/min)
                time.sleep(3.5)  # ~17 calls/min max, safe margin

                rerank_response = self.cohere_client.rerank(
                    model="rerank-v3.5",
                    query=query,
                    documents=[c["text"] for c in candidates],
                    top_n=top_k
                )

                reranked = []
                for r in rerank_response.results:
                    candidate = candidates[r.index]
                    candidate["rerank_score"] = r.relevance_score
                    reranked.append(candidate)
                candidates = reranked
            except Exception as e:
                if "429" not in str(e):
                    print(f"Reranking error: {e}")
                candidates = candidates[:top_k]
        else:
            candidates = candidates[:top_k]

        latency = (time.time() - start_time) * 1000
        return candidates, latency

    def evaluate(self, queries: List[LaMP_Query], profiles: List[LaMP_Profile]) -> Dict[str, Any]:
        """ë²¤ì¹˜ë§ˆí¬ í‰ê°€ ì‹¤í–‰"""
        results = {
            "before": {"hits": [], "mrr": [], "ndcg": [], "precision": [], "recall": [], "latency": []},
            "after": {"hits": [], "mrr": [], "ndcg": [], "precision": [], "recall": [], "latency": []}
        }

        total = len(queries)

        for idx, query in enumerate(queries):
            print(f"\rí‰ê°€ ì¤‘... {idx+1}/{total}", end="", flush=True)

            relevant_ids = set(query.relevant_profile_ids)

            # Before (2-stage) í‰ê°€
            before_results, before_latency = self.search_before(query.query_text, query.user_id)
            before_retrieved = [r["item_id"] for r in before_results]

            before_metrics = self._calculate_metrics(before_retrieved, relevant_ids)
            results["before"]["hits"].append(before_metrics["hit@1"])
            results["before"]["mrr"].append(before_metrics["mrr"])
            results["before"]["ndcg"].append(before_metrics["ndcg@5"])
            results["before"]["precision"].append(before_metrics["precision@5"])
            results["before"]["recall"].append(before_metrics["recall@5"])
            results["before"]["latency"].append(before_latency)

            # After (3-stage) í‰ê°€
            after_results, after_latency = self.search_after(query.query_text, query.user_id)
            after_retrieved = [r["item_id"] for r in after_results]

            after_metrics = self._calculate_metrics(after_retrieved, relevant_ids)
            results["after"]["hits"].append(after_metrics["hit@1"])
            results["after"]["mrr"].append(after_metrics["mrr"])
            results["after"]["ndcg"].append(after_metrics["ndcg@5"])
            results["after"]["precision"].append(after_metrics["precision@5"])
            results["after"]["recall"].append(after_metrics["recall@5"])
            results["after"]["latency"].append(after_latency)

        print("\n")

        # í‰ê·  ê³„ì‚°
        summary = {}
        for method in ["before", "after"]:
            summary[method] = {
                "hit_rate@1": np.mean(results[method]["hits"]),
                "mrr": np.mean(results[method]["mrr"]),
                "ndcg@5": np.mean(results[method]["ndcg"]),
                "precision@5": np.mean(results[method]["precision"]),
                "recall@5": np.mean(results[method]["recall"]),
                "avg_latency_ms": np.mean(results[method]["latency"]),
                "p95_latency_ms": np.percentile(results[method]["latency"], 95)
            }

        return summary

    def _calculate_metrics(self, retrieved: List[str], relevant: set) -> Dict[str, float]:
        """ê²€ìƒ‰ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        # Hit@1
        hit_at_1 = 1.0 if retrieved and retrieved[0] in relevant else 0.0

        # MRR
        mrr = 0.0
        for i, doc_id in enumerate(retrieved):
            if doc_id in relevant:
                mrr = 1.0 / (i + 1)
                break

        # NDCG@5
        dcg = 0.0
        for i, doc_id in enumerate(retrieved[:5]):
            if doc_id in relevant:
                dcg += 1.0 / np.log2(i + 2)

        idcg = sum(1.0 / np.log2(i + 2) for i in range(min(len(relevant), 5)))
        ndcg = dcg / idcg if idcg > 0 else 0.0

        # Precision@5
        relevant_in_top5 = sum(1 for doc_id in retrieved[:5] if doc_id in relevant)
        precision = relevant_in_top5 / 5

        # Recall@5
        recall = relevant_in_top5 / len(relevant) if relevant else 0.0

        return {
            "hit@1": hit_at_1,
            "mrr": mrr,
            "ndcg@5": ndcg,
            "precision@5": precision,
            "recall@5": recall
        }


async def main():
    print("=" * 70)
    print("LaMP (Language Model Personalization) Benchmark")
    print("2-stage vs 3-stage íŒŒì´í”„ë¼ì¸ ë¹„êµ")
    print("=" * 70)
    print()

    benchmark = LaMP_Benchmark()

    # 1. ë°ì´í„° ìƒì„±
    print("ğŸ“Š LaMP ìŠ¤íƒ€ì¼ ê°œì¸í™” ë°ì´í„° ìƒì„± ì¤‘...")
    profiles, queries = benchmark.generate_lamp_data(num_users=10, items_per_user=20)
    print(f"   - ì‚¬ìš©ì ìˆ˜: {len(profiles)}")
    print(f"   - ì´ í”„ë¡œí•„ ì•„ì´í…œ: {sum(len(p.profile_items) for p in profiles)}")
    print(f"   - ì¿¼ë¦¬ ìˆ˜: {len(queries)}")
    print()

    # 2. ì¸ë±ì‹±
    print("ğŸ”§ Qdrant ì»¬ë ‰ì…˜ ì„¤ì • ë° ì¸ë±ì‹±...")
    benchmark.setup_collection()
    benchmark.index_profiles(profiles)
    print()

    # 3. í‰ê°€ ì‹¤í–‰
    print("ğŸ§ª ë²¤ì¹˜ë§ˆí¬ í‰ê°€ ì‹¤í–‰...")
    print("-" * 70)
    results = benchmark.evaluate(queries, profiles)

    # 4. ê²°ê³¼ ì¶œë ¥
    print("=" * 70)
    print("ğŸ“ˆ LaMP Benchmark ê²°ê³¼")
    print("=" * 70)
    print()

    print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("â”‚ Metric              â”‚ Before (2-stage) â”‚ After (3-stage)  â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")

    metrics = [
        ("Hit Rate@1", "hit_rate@1", "{:.1%}"),
        ("MRR", "mrr", "{:.3f}"),
        ("NDCG@5", "ndcg@5", "{:.3f}"),
        ("Precision@5", "precision@5", "{:.3f}"),
        ("Recall@5", "recall@5", "{:.3f}"),
        ("Avg Latency (ms)", "avg_latency_ms", "{:.1f}"),
        ("P95 Latency (ms)", "p95_latency_ms", "{:.1f}")
    ]

    for label, key, fmt in metrics:
        before_val = results["before"][key]
        after_val = results["after"][key]

        if key.endswith("latency_ms"):
            # ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
            diff = before_val - after_val
            indicator = "â¬‡ï¸" if diff > 0 else "â¬†ï¸"
        else:
            # ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ
            diff = after_val - before_val
            indicator = "â¬†ï¸" if diff > 0 else "â¬‡ï¸" if diff < 0 else "â¡ï¸"

        before_str = fmt.format(before_val)
        after_str = fmt.format(after_val) + f" {indicator}"

        print(f"â”‚ {label:<19} â”‚ {before_str:>16} â”‚ {after_str:>16} â”‚")

    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    print()

    # íŒŒì´í”„ë¼ì¸ ì„¤ëª…
    print("ğŸ“‹ íŒŒì´í”„ë¼ì¸ êµ¬ì„±:")
    print("   Before (2-stage): Vector Search â†’ Cohere Reranking")
    print("   After (3-stage):  Vector Search â†’ BM25 Hybrid â†’ Cohere Reranking")
    print()

    # ë¶„ì„
    print("ğŸ“Š ë¶„ì„:")
    hit_diff = (results["after"]["hit_rate@1"] - results["before"]["hit_rate@1"]) * 100
    mrr_diff = (results["after"]["mrr"] - results["before"]["mrr"]) * 100
    latency_diff = results["after"]["avg_latency_ms"] - results["before"]["avg_latency_ms"]

    if hit_diff > 0:
        print(f"   âœ… Hit Rate@1ì´ {hit_diff:.1f}%p í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.")
    elif hit_diff < 0:
        print(f"   âš ï¸ Hit Rate@1ì´ {abs(hit_diff):.1f}%p ê°ì†Œí–ˆìŠµë‹ˆë‹¤.")
    else:
        print(f"   â¡ï¸ Hit Rate@1ì€ ë™ì¼í•©ë‹ˆë‹¤.")

    if mrr_diff > 0:
        print(f"   âœ… MRRì´ {mrr_diff:.1f}%p í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.")
    elif mrr_diff < 0:
        print(f"   âš ï¸ MRRì´ {abs(mrr_diff):.1f}%p ê°ì†Œí–ˆìŠµë‹ˆë‹¤.")

    print(f"   â±ï¸ LatencyëŠ” {latency_diff:+.1f}ms ì°¨ì´ë‚©ë‹ˆë‹¤.")
    print()

    print("ğŸ’¡ LaMP ë²¤ì¹˜ë§ˆí¬ íŠ¹ì„±:")
    print("   - ê°œì¸í™” ê²€ìƒ‰ íƒœìŠ¤í¬ë¡œ, ì‚¬ìš©ìë³„ ê³¼ê±° í™œë™ ê¸°ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰")
    print("   - ì œí’ˆ ì¹´í…Œê³ ë¦¬/í‚¤ì›Œë“œ ê¸°ë°˜ í•„í„°ë§ì´ ì¤‘ìš”í•œ íƒœìŠ¤í¬")
    print("   - BM25ê°€ ì¹´í…Œê³ ë¦¬/ì œí’ˆëª… ë§¤ì¹­ì—ì„œ ê°•ì ì„ ë³´ì¼ ìˆ˜ ìˆìŒ")
    print()

    # ê²°ê³¼ ì €ì¥
    output_file = "/tmp/lamp_benchmark_results.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump({
            "benchmark": "LaMP",
            "timestamp": datetime.now().isoformat(),
            "config": {
                "num_users": len(profiles),
                "items_per_user": 20,
                "num_queries": len(queries),
                "embedding_model": "text-embedding-3-large",
                "reranking": "cohere/rerank-v3.5"
            },
            "results": results
        }, f, indent=2, ensure_ascii=False)

    print(f"ğŸ“ ê²°ê³¼ ì €ì¥: {output_file}")


if __name__ == "__main__":
    asyncio.run(main())
