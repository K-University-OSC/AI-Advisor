"""
Knowledge Graph Benchmark í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
ì§€ì‹ ê·¸ë˜í”„ì˜ íš¨ê³¼ë¥¼ ê²€ì¦í•˜ê¸° ìœ„í•œ ë²¤ì¹˜ë§ˆí¬

ë¹„êµ ëŒ€ìƒ:
1. Vector Only - ë²¡í„° ê²€ìƒ‰ë§Œ
2. Vector + Reranker (BGE) - ë²¡í„° + BGE ë¦¬ë­í‚¹
3. Vector + KG - ë²¡í„° + ì§€ì‹ ê·¸ë˜í”„
4. Vector + KG + Reranker - ë²¡í„° + ì§€ì‹ ê·¸ë˜í”„ + BGE ë¦¬ë­í‚¹

í‰ê°€ ì§€í‘œ: Entity Recall, Relation Recall, Multi-hop Accuracy, Latency
"""

import asyncio
import json
import os
import sys
import time
import random
from datetime import datetime
from typing import List, Dict, Any, Tuple, Optional
from dataclasses import dataclass
import uuid
import numpy as np

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from dotenv import load_dotenv
load_dotenv()

from services.memory_service import (
    KnowledgeGraph, PIPELINE_MODES, NETWORKX_AVAILABLE
)

print(f"âœ… NetworkX Available: {NETWORKX_AVAILABLE}")
print(f"âœ… Pipeline Modes: {list(PIPELINE_MODES.keys())}")


@dataclass
class TestScenario:
    """í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤"""
    scenario_id: str
    description: str
    entities: List[Dict]  # [{"value": "Python", "type": "technology"}]
    relations: List[Dict]  # [{"subject": "user", "relation": "uses", "object": "Python"}]
    queries: List[Dict]  # [{"query": "...", "expected_entities": [...], "expected_relations": [...]}]


class KnowledgeGraphBenchmark:
    """Knowledge Graph ë²¤ì¹˜ë§ˆí¬"""

    def __init__(self):
        self.scenarios: List[TestScenario] = []

    def generate_test_scenarios(self) -> List[TestScenario]:
        """í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±"""
        scenarios = [
            # ì‹œë‚˜ë¦¬ì˜¤ 1: ê°œë°œì í”„ë¡œí•„
            TestScenario(
                scenario_id="developer_1",
                description="Python ê°œë°œìì˜ ê¸°ìˆ  ìŠ¤íƒ",
                entities=[
                    {"value": "Python", "type": "technology", "confidence": 0.95},
                    {"value": "FastAPI", "type": "technology", "confidence": 0.9},
                    {"value": "PostgreSQL", "type": "technology", "confidence": 0.85},
                    {"value": "Docker", "type": "technology", "confidence": 0.9},
                    {"value": "ë„¤ì´ë²„", "type": "organization", "confidence": 0.8}
                ],
                relations=[
                    {"subject": "user", "subject_type": "person", "relation": "uses", "object": "Python", "object_type": "technology", "confidence": 0.95},
                    {"subject": "user", "subject_type": "person", "relation": "uses", "object": "FastAPI", "object_type": "technology", "confidence": 0.9},
                    {"subject": "user", "subject_type": "person", "relation": "uses", "object": "PostgreSQL", "object_type": "technology", "confidence": 0.85},
                    {"subject": "user", "subject_type": "person", "relation": "uses", "object": "Docker", "object_type": "technology", "confidence": 0.9},
                    {"subject": "user", "subject_type": "person", "relation": "works_at", "object": "ë„¤ì´ë²„", "object_type": "organization", "confidence": 0.8},
                    {"subject": "FastAPI", "subject_type": "technology", "relation": "uses", "object": "Python", "object_type": "technology", "confidence": 0.95}  # 2-hop relation
                ],
                queries=[
                    {"query": "Python", "expected_entities": ["Python", "FastAPI"], "hops": 1},
                    {"query": "ì–´ë–¤ ê¸°ìˆ  ì‚¬ìš©í•´ìš”?", "expected_entities": ["Python", "FastAPI", "PostgreSQL", "Docker"], "hops": 1},
                    {"query": "íšŒì‚¬", "expected_entities": ["ë„¤ì´ë²„"], "hops": 1},
                    {"query": "FastAPI ê´€ë ¨ ê¸°ìˆ ", "expected_entities": ["FastAPI", "Python"], "hops": 2}  # multi-hop
                ]
            ),

            # ì‹œë‚˜ë¦¬ì˜¤ 2: í•™ìƒ í”„ë¡œí•„
            TestScenario(
                scenario_id="student_1",
                description="ì»´í“¨í„°ê³µí•™ ì „ê³µ í•™ìƒ",
                entities=[
                    {"value": "ì„œìš¸ëŒ€í•™êµ", "type": "organization", "confidence": 0.95},
                    {"value": "ì»´í“¨í„°ê³µí•™", "type": "skill", "confidence": 0.9},
                    {"value": "ë¨¸ì‹ ëŸ¬ë‹", "type": "interest", "confidence": 0.85},
                    {"value": "2024ë…„ 2ì›”", "type": "date", "confidence": 0.9},
                    {"value": "AI ìŠ¤íƒ€íŠ¸ì—…", "type": "interest", "confidence": 0.8}
                ],
                relations=[
                    {"subject": "user", "subject_type": "person", "relation": "studies_at", "object": "ì„œìš¸ëŒ€í•™êµ", "object_type": "organization", "confidence": 0.95},
                    {"subject": "user", "subject_type": "person", "relation": "knows", "object": "ì»´í“¨í„°ê³µí•™", "object_type": "skill", "confidence": 0.9},
                    {"subject": "user", "subject_type": "person", "relation": "interested_in", "object": "ë¨¸ì‹ ëŸ¬ë‹", "object_type": "interest", "confidence": 0.85},
                    {"subject": "user", "subject_type": "person", "relation": "interested_in", "object": "AI ìŠ¤íƒ€íŠ¸ì—…", "object_type": "interest", "confidence": 0.8}
                ],
                queries=[
                    {"query": "í•™êµ", "expected_entities": ["ì„œìš¸ëŒ€í•™êµ"], "hops": 1},
                    {"query": "ì „ê³µ", "expected_entities": ["ì»´í“¨í„°ê³µí•™"], "hops": 1},
                    {"query": "ê´€ì‹¬ì‚¬", "expected_entities": ["ë¨¸ì‹ ëŸ¬ë‹", "AI ìŠ¤íƒ€íŠ¸ì—…"], "hops": 1},
                    {"query": "ì„œìš¸ëŒ€ì—ì„œ ë°°ìš´ ê²ƒ", "expected_entities": ["ì„œìš¸ëŒ€í•™êµ", "ì»´í“¨í„°ê³µí•™"], "hops": 2}
                ]
            ),

            # ì‹œë‚˜ë¦¬ì˜¤ 3: ë³µí•© ê´€ê³„
            TestScenario(
                scenario_id="complex_1",
                description="ë³µí•©ì ì¸ ì—”í‹°í‹° ê´€ê³„",
                entities=[
                    {"value": "LangChain", "type": "technology", "confidence": 0.95},
                    {"value": "RAG", "type": "concept", "confidence": 0.9},
                    {"value": "OpenAI", "type": "organization", "confidence": 0.95},
                    {"value": "GPT-4", "type": "product", "confidence": 0.9},
                    {"value": "ì±—ë´‡ í”„ë¡œì íŠ¸", "type": "project", "confidence": 0.85}
                ],
                relations=[
                    {"subject": "user", "subject_type": "person", "relation": "uses", "object": "LangChain", "object_type": "technology", "confidence": 0.95},
                    {"subject": "user", "subject_type": "person", "relation": "knows", "object": "RAG", "object_type": "concept", "confidence": 0.9},
                    {"subject": "user", "subject_type": "person", "relation": "uses", "object": "GPT-4", "object_type": "product", "confidence": 0.9},
                    {"subject": "user", "subject_type": "person", "relation": "works_on", "object": "ì±—ë´‡ í”„ë¡œì íŠ¸", "object_type": "project", "confidence": 0.85},
                    {"subject": "LangChain", "subject_type": "technology", "relation": "uses", "object": "RAG", "object_type": "concept", "confidence": 0.9},
                    {"subject": "GPT-4", "subject_type": "product", "relation": "created", "object": "OpenAI", "object_type": "organization", "confidence": 0.95}
                ],
                queries=[
                    {"query": "RAG ê´€ë ¨ ê¸°ìˆ ", "expected_entities": ["RAG", "LangChain"], "hops": 2},
                    {"query": "í”„ë¡œì íŠ¸", "expected_entities": ["ì±—ë´‡ í”„ë¡œì íŠ¸"], "hops": 1},
                    {"query": "GPT", "expected_entities": ["GPT-4", "OpenAI"], "hops": 2},
                    {"query": "ì–´ë–¤ LLM ì¨ìš”?", "expected_entities": ["GPT-4", "LangChain"], "hops": 1}
                ]
            ),

            # ì‹œë‚˜ë¦¬ì˜¤ 4: ì·¨ë¯¸/ë¼ì´í”„ìŠ¤íƒ€ì¼
            TestScenario(
                scenario_id="lifestyle_1",
                description="ì·¨ë¯¸ì™€ ë¼ì´í”„ìŠ¤íƒ€ì¼",
                entities=[
                    {"value": "ê¸°íƒ€", "type": "interest", "confidence": 0.9},
                    {"value": "ë½ ìŒì•…", "type": "interest", "confidence": 0.85},
                    {"value": "í—¬ìŠ¤", "type": "interest", "confidence": 0.9},
                    {"value": "ë§¤ì¼ ì•„ì¹¨ 6ì‹œ", "type": "concept", "confidence": 0.8},
                    {"value": "ë‹¨ë°±ì§ˆ ë³´ì¶©ì œ", "type": "product", "confidence": 0.75}
                ],
                relations=[
                    {"subject": "user", "subject_type": "person", "relation": "interested_in", "object": "ê¸°íƒ€", "object_type": "interest", "confidence": 0.9},
                    {"subject": "user", "subject_type": "person", "relation": "prefers", "object": "ë½ ìŒì•…", "object_type": "interest", "confidence": 0.85},
                    {"subject": "user", "subject_type": "person", "relation": "interested_in", "object": "í—¬ìŠ¤", "object_type": "interest", "confidence": 0.9},
                    {"subject": "user", "subject_type": "person", "relation": "uses", "object": "ë‹¨ë°±ì§ˆ ë³´ì¶©ì œ", "object_type": "product", "confidence": 0.75},
                    {"subject": "ê¸°íƒ€", "subject_type": "interest", "relation": "uses", "object": "ë½ ìŒì•…", "object_type": "interest", "confidence": 0.8}
                ],
                queries=[
                    {"query": "ì·¨ë¯¸", "expected_entities": ["ê¸°íƒ€", "í—¬ìŠ¤"], "hops": 1},
                    {"query": "ìŒì•…", "expected_entities": ["ê¸°íƒ€", "ë½ ìŒì•…"], "hops": 2},
                    {"query": "ìš´ë™", "expected_entities": ["í—¬ìŠ¤", "ë‹¨ë°±ì§ˆ ë³´ì¶©ì œ"], "hops": 2},
                    {"query": "ê±´ê°• ê´€ë¦¬", "expected_entities": ["í—¬ìŠ¤", "ë‹¨ë°±ì§ˆ ë³´ì¶©ì œ"], "hops": 1}
                ]
            ),

            # ì‹œë‚˜ë¦¬ì˜¤ 5: ê²½ë ¥/ì§ì¥
            TestScenario(
                scenario_id="career_1",
                description="ê²½ë ¥ ë° ì§ì¥ ì •ë³´",
                entities=[
                    {"value": "ì‚¼ì„±ì „ì", "type": "organization", "confidence": 0.95},
                    {"value": "ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´", "type": "skill", "confidence": 0.9},
                    {"value": "5ë…„", "type": "date", "confidence": 0.85},
                    {"value": "íŒ€ì¥", "type": "concept", "confidence": 0.8},
                    {"value": "ë°˜ë„ì²´", "type": "concept", "confidence": 0.75}
                ],
                relations=[
                    {"subject": "user", "subject_type": "person", "relation": "works_at", "object": "ì‚¼ì„±ì „ì", "object_type": "organization", "confidence": 0.95},
                    {"subject": "user", "subject_type": "person", "relation": "knows", "object": "ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´", "object_type": "skill", "confidence": 0.9},
                    {"subject": "ì‚¼ì„±ì „ì", "subject_type": "organization", "relation": "works_on", "object": "ë°˜ë„ì²´", "object_type": "concept", "confidence": 0.85}
                ],
                queries=[
                    {"query": "ì§ì¥", "expected_entities": ["ì‚¼ì„±ì „ì"], "hops": 1},
                    {"query": "ì§ì—…", "expected_entities": ["ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´"], "hops": 1},
                    {"query": "ì‚¼ì„±ì—ì„œ í•˜ëŠ” ì¼", "expected_entities": ["ì‚¼ì„±ì „ì", "ë°˜ë„ì²´"], "hops": 2},
                    {"query": "ê²½ë ¥", "expected_entities": ["ì‚¼ì„±ì „ì", "ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´", "5ë…„"], "hops": 1}
                ]
            )
        ]

        self.scenarios = scenarios
        return scenarios

    def build_knowledge_graph(self, scenario: TestScenario) -> KnowledgeGraph:
        """ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì§€ì‹ ê·¸ë˜í”„ êµ¬ì¶•"""
        kg = KnowledgeGraph()

        # ì—”í‹°í‹° ì¶”ê°€
        for entity in scenario.entities:
            kg.add_entity(
                entity_value=entity["value"],
                entity_type=entity["type"],
                memory_id=f"{scenario.scenario_id}_{entity['value']}",
                confidence=entity.get("confidence", 0.8)
            )

        # ê´€ê³„ ì¶”ê°€
        for relation in scenario.relations:
            kg.add_relation(
                subject_value=relation["subject"],
                subject_type=relation["subject_type"],
                relation_type=relation["relation"],
                object_value=relation["object"],
                object_type=relation["object_type"],
                memory_id=f"{scenario.scenario_id}_rel_{relation['object']}",
                confidence=relation.get("confidence", 0.8)
            )

        return kg

    def evaluate_entity_retrieval(
        self,
        kg: KnowledgeGraph,
        query: str,
        expected_entities: List[str],
        max_hops: int = 2
    ) -> Dict[str, Any]:
        """ì—”í‹°í‹° ê²€ìƒ‰ í‰ê°€"""
        start_time = time.time()

        # 1. ì§ì ‘ ì—”í‹°í‹° ë§¤ì¹­
        found_entities = kg.find_entities(query)

        # 2. ê·¸ë˜í”„ íƒìƒ‰ìœ¼ë¡œ í™•ì¥
        if found_entities:
            start_nodes = [e["node_id"] for e in found_entities[:3]]
            traversed = kg.traverse(start_nodes, max_hops=max_hops)
            all_entity_values = set(
                item["entity_value"].lower() for item in traversed
                if item.get("entity_value")
            )
        else:
            all_entity_values = set()

        latency = (time.time() - start_time) * 1000

        # ë©”íŠ¸ë¦­ ê³„ì‚°
        expected_set = set(e.lower() for e in expected_entities)
        retrieved_set = all_entity_values

        hits = expected_set & retrieved_set
        precision = len(hits) / len(retrieved_set) if retrieved_set else 0.0
        recall = len(hits) / len(expected_set) if expected_set else 0.0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0

        return {
            "query": query,
            "expected": list(expected_entities),
            "retrieved": list(all_entity_values),
            "hits": list(hits),
            "precision": precision,
            "recall": recall,
            "f1": f1,
            "latency_ms": latency
        }

    def run_benchmark(self) -> Dict[str, Any]:
        """ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        print("=" * 70)
        print("Knowledge Graph Benchmark")
        print("=" * 70)
        print()

        if not NETWORKX_AVAILABLE:
            print("âŒ NetworkX not available. Cannot run benchmark.")
            return {"error": "NetworkX not available"}

        # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±
        print("ğŸ“Š í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì¤‘...")
        scenarios = self.generate_test_scenarios()
        print(f"   - ì‹œë‚˜ë¦¬ì˜¤ ìˆ˜: {len(scenarios)}")
        print()

        all_results = []
        scenario_results = {}

        for scenario in scenarios:
            print(f"\nğŸ“‹ ì‹œë‚˜ë¦¬ì˜¤: {scenario.scenario_id} - {scenario.description}")

            # ê·¸ë˜í”„ êµ¬ì¶•
            kg = self.build_knowledge_graph(scenario)
            stats = kg.get_stats()
            print(f"   - ë…¸ë“œ: {stats['total_nodes']}, ì—£ì§€: {stats['total_edges']}")

            scenario_metrics = []

            for q_data in scenario.queries:
                result = self.evaluate_entity_retrieval(
                    kg=kg,
                    query=q_data["query"],
                    expected_entities=q_data["expected_entities"],
                    max_hops=q_data.get("hops", 2)
                )
                result["hops"] = q_data.get("hops", 2)
                scenario_metrics.append(result)
                all_results.append(result)

                print(f"   Query: \"{q_data['query']}\" -> Recall: {result['recall']:.1%}, F1: {result['f1']:.1%}")

            # ì‹œë‚˜ë¦¬ì˜¤ë³„ í‰ê· 
            scenario_results[scenario.scenario_id] = {
                "description": scenario.description,
                "num_queries": len(scenario.queries),
                "avg_precision": np.mean([r["precision"] for r in scenario_metrics]),
                "avg_recall": np.mean([r["recall"] for r in scenario_metrics]),
                "avg_f1": np.mean([r["f1"] for r in scenario_metrics]),
                "avg_latency_ms": np.mean([r["latency_ms"] for r in scenario_metrics])
            }

        # ì „ì²´ í‰ê· 
        overall = {
            "total_queries": len(all_results),
            "avg_precision": np.mean([r["precision"] for r in all_results]),
            "avg_recall": np.mean([r["recall"] for r in all_results]),
            "avg_f1": np.mean([r["f1"] for r in all_results]),
            "avg_latency_ms": np.mean([r["latency_ms"] for r in all_results]),
            "p95_latency_ms": np.percentile([r["latency_ms"] for r in all_results], 95)
        }

        # í™‰ ìˆ˜ë³„ ë¶„ì„
        hop_analysis = {}
        for hops in [1, 2]:
            hop_results = [r for r in all_results if r.get("hops") == hops]
            if hop_results:
                hop_analysis[f"{hops}-hop"] = {
                    "count": len(hop_results),
                    "avg_recall": np.mean([r["recall"] for r in hop_results]),
                    "avg_f1": np.mean([r["f1"] for r in hop_results])
                }

        return {
            "overall": overall,
            "by_scenario": scenario_results,
            "by_hops": hop_analysis,
            "detailed_results": all_results
        }


def print_results(results: Dict[str, Any]):
    """ê²°ê³¼ ì¶œë ¥"""
    print("\n" + "=" * 70)
    print("ğŸ“ˆ Knowledge Graph Benchmark ê²°ê³¼")
    print("=" * 70)

    overall = results.get("overall", {})
    print(f"\nğŸ“Š ì „ì²´ ì„±ëŠ¥:")
    print(f"   - Total Queries: {overall.get('total_queries', 0)}")
    print(f"   - Avg Precision: {overall.get('avg_precision', 0):.1%}")
    print(f"   - Avg Recall: {overall.get('avg_recall', 0):.1%}")
    print(f"   - Avg F1: {overall.get('avg_f1', 0):.1%}")
    print(f"   - Avg Latency: {overall.get('avg_latency_ms', 0):.2f}ms")
    print(f"   - P95 Latency: {overall.get('p95_latency_ms', 0):.2f}ms")

    print(f"\nğŸ“Š í™‰ ìˆ˜ë³„ ë¶„ì„:")
    for hop_key, hop_data in results.get("by_hops", {}).items():
        print(f"   {hop_key}: Recall={hop_data['avg_recall']:.1%}, F1={hop_data['avg_f1']:.1%} ({hop_data['count']} queries)")

    print(f"\nğŸ“Š ì‹œë‚˜ë¦¬ì˜¤ë³„ ì„±ëŠ¥:")
    for scenario_id, scenario_data in results.get("by_scenario", {}).items():
        print(f"   {scenario_id}: F1={scenario_data['avg_f1']:.1%}, Recall={scenario_data['avg_recall']:.1%}")

    print()

    # ë¶„ì„ ìš”ì•½
    print("ğŸ“‹ Knowledge Graph ë¶„ì„:")
    print("   â€¢ 1-hop ê²€ìƒ‰: ì§ì ‘ ì—°ê²°ëœ ì—”í‹°í‹° ê²€ìƒ‰ (ë†’ì€ ì •í™•ë„)")
    print("   â€¢ 2-hop ê²€ìƒ‰: ê°„ì ‘ ì—°ê²°ëœ ì—”í‹°í‹° ê²€ìƒ‰ (ë³µí•© ì¶”ë¡ )")
    print("   â€¢ NetworkX ê·¸ë˜í”„ íƒìƒ‰: BFS ê¸°ë°˜ ë¹ ë¥¸ íƒìƒ‰")
    print()

    if overall.get("avg_f1", 0) >= 0.7:
        print("âœ… Knowledge Graphê°€ íš¨ê³¼ì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤!")
    elif overall.get("avg_f1", 0) >= 0.5:
        print("âš ï¸ Knowledge Graphê°€ ì–´ëŠ ì •ë„ íš¨ê³¼ì ì´ì§€ë§Œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        print("âŒ Knowledge Graph ì„±ëŠ¥ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")


async def main():
    benchmark = KnowledgeGraphBenchmark()
    results = benchmark.run_benchmark()

    print_results(results)

    # ê²°ê³¼ ì €ì¥
    output_file = "/tmp/knowledge_graph_benchmark_results.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump({
            "benchmark": "Knowledge Graph Evaluation",
            "timestamp": datetime.now().isoformat(),
            **results
        }, f, indent=2, ensure_ascii=False, default=str)

    print(f"ğŸ“ ê²°ê³¼ ì €ì¥: {output_file}")


if __name__ == "__main__":
    asyncio.run(main())
